[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Synthetic Population Catalyst",
    "section": "",
    "text": "The Synthetic Population Catalyst (SPC) makes it easier for researchers to work with synthetic population data in England. It combines a variety of data sources and outputs a single file in protocol buffer format, describing the population in a given study area. The data includes demographic, health, and daily activity data per person, and information about the venues where people conduct activities.\nYou can use SPC output to catalyze your own project. Rather than join together many raw data sources yourself and deal with missing and messy data, you can leverage SPC’s effort and well-documented schema.\nTo get started:\n\nDownload sample data for a county in England\nExplore how to use the data\nIf you need a different study area, build and then run SPC\n\nYou can also download this site as a PDF and find all code on Github.\nThis work was supported by Wave 1 of The UKRI Strategic Priorities Fund under the EPSRC Grant EP/W006022/1, particularly the “Ecosystem of Digital Twins”\nand “Shocks and Resilience” themes within that grant & The Alan Turing Institute"
  },
  {
    "objectID": "outputs.html#citing",
    "href": "outputs.html#citing",
    "title": "2  SPC Outputs",
    "section": "2.1 Citing",
    "text": "2.1 Citing\nIf you use SPC code or data in your work, please cite using the Zenodo DOI (using the bottom-right tool to generate the citation)."
  },
  {
    "objectID": "outputs.html#versioning",
    "href": "outputs.html#versioning",
    "title": "2  SPC Outputs",
    "section": "2.2 Versioning",
    "text": "2.2 Versioning\nOver time, we may add more data to SPC or change the schema. Protocol buffers are designed to let combinations of new/old code and data files work together, but we don’t intend to use this feature. We may make breaking changes, like deleting fields. We’ll release a new version of the schema and output data every time and document it here. You should depend on a specific version of the data output in your code, so new releases don’t affect you until you decide to update.\n\nv1: released 25/04/2022, schema\nv1.1, released 27/05/2022, schema\n\nadded pwkstat, salary_hourly, salary_yearly, and idp\nreorganized Identifiers and Employment attributes\nnon-breaking change added 02/08/2022: added bmi_new field\n\nv1.2, released 29/12/2022, schema\n\nswitched to proto2 and made some fields optional\nadjusted some numeric enum values to match ONS\n\nv2, released 09/03/2023, schema\n\nnew per-person and per-household fields\nvarious changes to existing fields (adjusting enum number, removing the BMI enum, etc)\nadding time-use diaries\nexpanding to Wales\nadding multiple years of output"
  },
  {
    "objectID": "england_outputs.html#citing",
    "href": "england_outputs.html#citing",
    "title": "3  Outputs for England Counties",
    "section": "3.1 Citing",
    "text": "3.1 Citing\nIf you use SPC code or data in your work, please cite using the Zenodo DOI (using the bottom-right tool to generate the citation)."
  },
  {
    "objectID": "wales_outputs.html#citing",
    "href": "wales_outputs.html#citing",
    "title": "4  Outputs for Wales Counties",
    "section": "4.1 Citing",
    "text": "4.1 Citing\nIf you use SPC code or data in your work, please cite using the Zenodo DOI (using the bottom-right tool to generate the citation)."
  },
  {
    "objectID": "use_output.html#javascript",
    "href": "use_output.html#javascript",
    "title": "5  Using the SPC output file",
    "section": "5.1 Javascript",
    "text": "5.1 Javascript\nWe have a web app using Svelte to interactively explore SPC data. Its source code is great reference for how to use the proto output."
  },
  {
    "objectID": "use_output.html#python",
    "href": "use_output.html#python",
    "title": "5  Using the SPC output file",
    "section": "5.2 Python",
    "text": "5.2 Python\nTo work with SPC protobufs in Python, you need two dependencies setup:\n\nThe protobuf library\n\nYou can install system-wide with pip install protobuf\nOr add as a dependency to a conda, poetry, etc environment\n\nThe generated Python library, synthpop_pb2.py\n\nYou can download a copy of this file into your codebase, then import synthpop_pb2\nYou can also generate the file yourself, following the docs: protoc --python_out=python/ synthpop.proto\n\n\n\n5.2.1 Converting to Pandas data-frames and CSV\nThe schema expresses relationships between people, households, and venues that can’t all be captured by a simple 2D table. Nevertheless, you can extract per-person information and express as a dataframe or CSV file. See this example Python script for inspiration. You can try it out:\n# Download a file\nwget https://ramp0storage.blob.core.windows.net/spc-output/v1/rutland.pb.gz\n# Uncompress\ngunzip rutland.pb.gz\n# Convert the .pb to JSON\npython3 python/protobuf_to_csv.py --input_path data/output/rutland.pb\n# View the output\nless people.csv\n\n\n5.2.2 Converting .pb file to JSON format\nTo interactively explore the data, viewing JSON is much easier. It shows the same structure as the protobuf, but in a human-readable text format. The example below uses a small Python script:\n# Download a file\nwget https://ramp0storage.blob.core.windows.net/spc-output/v1/rutland.pb.gz\n# Uncompress\ngunzip rutland.pb.gz\n# Convert the .pb to JSON\npython3 python/protobuf_to_json.py data/output/rutland.pb > rutland.json\n# View the output\nless rutland.json\n\n\n5.2.3 Converting to numpy arrays\nThe ASPICS project simulates the spread of COVID through a population. The code uses numpy, and this script converts the protobuf to a bunch of different numpy arrays.\nNote the ASPICS code doesn’t keep using the generated Python protobuf classes for the rest of the pipeline. Data frames and numpy arrays may be more familiar and appropriate. The protobuf is a format optimized for reading and writing; you don’t need to use it throughout all of your model code.\n\n\n5.2.4 Visualizing venues\nUse this script to read a protobuf file, then draws a dot for every venue, color-coded by activity."
  },
  {
    "objectID": "installation.html#dependencies",
    "href": "installation.html#dependencies",
    "title": "6  Installation",
    "section": "6.1 Dependencies",
    "text": "6.1 Dependencies\n\nRust: The latest stable version of Rust: https://www.rust-lang.org/tools/install"
  },
  {
    "objectID": "installation.html#compiling-spc",
    "href": "installation.html#compiling-spc",
    "title": "6  Installation",
    "section": "6.2 Compiling SPC",
    "text": "6.2 Compiling SPC\ngit clone https://github.com/alan-turing-institute/uatk-spc/\ncd uatk-spc\n# The next command will take a few minutes the first time you do it, to build external dependencies\ncargo build --release"
  },
  {
    "objectID": "installation.html#troubleshooting-downloading",
    "href": "installation.html#troubleshooting-downloading",
    "title": "6  Installation",
    "section": "6.3 Troubleshooting downloading",
    "text": "6.3 Troubleshooting downloading\nIf you get an error No such file or directory (os error 2) it might be because a previous attempt to run SPC failed, and some necessary files were not fully downloaded. In these cases you could try deleting the data/raw_data directory and then running SPC again. It should automatically try to download the big files again.\nIf you have trouble downloading any of the large files, you can download them manually. The logs will contain a line such as Downloading https://ramp0storage.blob.core.windows.net/nationaldata/QUANT_RAMP_spc.tar.gz to data/raw_data/nationaldata/QUANT_RAMP_spc.tar.gz. This tells you the URL to retrieve, and where to put the output file. Note that SPC won’t attempt to download files if they already exist, so if you wind up with a partially downloaded file, you have to manually remove it."
  },
  {
    "objectID": "custom_areas.html#specifying-the-area",
    "href": "custom_areas.html#specifying-the-area",
    "title": "7  Creating new study areas",
    "section": "7.1 Specifying the area",
    "text": "7.1 Specifying the area\nSPC takes a newline-separated list of MSOAs in the config/ directory as input, like this. You can generate this list from a LAD (local authority district). From the main SPC directory, run python scripts/select_msoas.py. Refer to data/raw_data/referencedata/lookUp.csv (only available after running SPC once) for all geographies available.\nThis script will create a new file, config/your_region.txt."
  },
  {
    "objectID": "custom_areas.html#run-spc-for-the-new-area",
    "href": "custom_areas.html#run-spc-for-the-new-area",
    "title": "7  Creating new study areas",
    "section": "7.2 Run SPC for the new area",
    "text": "7.2 Run SPC for the new area\nFrom the main directory, just run:\ncargo run --release -- config/your_region.txt\nThis will download some large files the first time. You’ll wind up with data/output/your_region.pb as output, as well as lots of intermediate files in data/raw_data/. The next time you run this command (even on a different study area), it should go much faster."
  },
  {
    "objectID": "custom_areas.html#optional-run-spc-for-lots-of-areas",
    "href": "custom_areas.html#optional-run-spc-for-lots-of-areas",
    "title": "7  Creating new study areas",
    "section": "7.3 (Optional) run SPC for lots of areas",
    "text": "7.3 (Optional) run SPC for lots of areas\nIf you want to run the program over lots of areas at once and are using Mac/Linux, you can use a for loop in a terminal to repeatedly run SPC over all files in the config directory. For example, this will run SPC on all .txt files in the config directory:\nfor file in config/*.csv; do cargo run --release -- config/$file; done"
  },
  {
    "objectID": "custom_areas.html#using-the-output",
    "href": "custom_areas.html#using-the-output",
    "title": "7  Creating new study areas",
    "section": "7.4 Using the output",
    "text": "7.4 Using the output\nAfter you generate the files, see here for how to use them in your project.\nIf you use SPC code or data in your work, please cite using the Zenodo DOI (using the bottom-right tool to generate the citation)."
  },
  {
    "objectID": "schema.html#understanding-the-schema",
    "href": "schema.html#understanding-the-schema",
    "title": "8  Data schema",
    "section": "8.1 Understanding the schema",
    "text": "8.1 Understanding the schema\nHere are some helpful tips for understanding the schema.\nEach .pb file contains exactly one Population message. In contrast to datasets consisting of multiple .csv files, just a single file contains everything. Some of the fields in Population are lists (of people and households) or maps (of venues keyed by activity, or of MSOAs). Unlike a flat .csv table, there may be more lists embedded later. Each Household has a list of members, for example.\nThe different objects refer to each other, forming a graph structure. The protobuf uses uint64 IDs to index into other lists. For example, if some household has members = [3, 10], then those two people can be found at population.people[3] and population.people[10]. Each of them will have the same household ID, pointing back to something in the population.households list."
  },
  {
    "objectID": "schema.html#flows-modelling-daily-activites",
    "href": "schema.html#flows-modelling-daily-activites",
    "title": "8  Data schema",
    "section": "8.2 Flows: modelling daily activites",
    "text": "8.2 Flows: modelling daily activites\nSPC models daily travel behavior of people as “flows.” Flows are broken down by by an activity – shopping/retail, attending primary or secondary school, working, or staying at home. For each activity type, a person has a list of venues where they may do that activity, weighted by a probability of going to that particular venue.\nNote that flows_per_activity is stored in InfoPerMSOA, not Person. The flows for retail and school are only known at the MSOA level, not individually. So given a particular Person object, you first look up their household’s MSOA – msoa = population.households[ person.household ].msoa and then look up flows for that MSOA – population.info_per_msoa[msoa].flows_per_activity.\nEach person has exactly 1 flow for home – it’s just person.household with probability 1. A person has 0 or 1 flows to work, based on the value of person.workplace.\nThis doesn’t mean that all people in the same MSOA share the same travel behavior. Each person has their own activity_durations field, based on time-use survey data. Even if two people share the same set of places where they may go shopping, one person may spend much more time on that activity than another.\nSee the ASPICS conversion script for all of this in action – it has a function to collapse a person’s flows down into a single weighted list.\nNote that per MSOA, very few venues are represented as destinations – 10 for retail and 5 for school. Only the most likely venues from QUANT are used."
  },
  {
    "objectID": "schema.html#flow-weights",
    "href": "schema.html#flow-weights",
    "title": "8  Data schema",
    "section": "8.3 Flow weights",
    "text": "8.3 Flow weights\nHow do you interpret the probabilities/weights for flows? If your model needs people to visit specific places each day, you could randomly sample a venue from the flows, weighting them appropriately. For retail, you may want to repeat this sampling every day of the simulation, so they visit different venues. For primary and secondary school, it may be more appropriate to sample once and store that for the simulation – a student probably doesn’t switch schools daily.\nAlternatively, you can follow what ASPICS does. Every day, each person logically visits all possible venues, but their interaction there (possibly receiving or transmitting COVID) is weighted by the probability of each venue."
  },
  {
    "objectID": "modelling_methods.html#join-with-the-health-surveys-and-uk-time-used-survey",
    "href": "modelling_methods.html#join-with-the-health-surveys-and-uk-time-used-survey",
    "title": "9  Modelling methods",
    "section": "9.1 Join with the Health Surveys and UK Time Used Survey",
    "text": "9.1 Join with the Health Surveys and UK Time Used Survey\nOnce merged into one dataset according to the matching key, the SPENSER data is enriched with the Health Surveys and UK Time Used Survey.\nAn individual among those sharing the same 5-year age group (see code for details of age groups for under 18) and sex is drawn from the participants of the Health Survey. This adds the id_HS, HEALTH_diabetes, HEALTH_bloodpressure, HEALTH_cvd, HEALTH_NMedecines, HEALTH_selfAssessed and HEALTH_lifeSat fields. This join is not spatially differentiated and other matching criteria (ethnicity and nssec8) were retained due to a lack of representativity inside the survey. The BMI field is the result of a more comprehensive modelling detailed below.\nEach individual that is not a head of household is assigned an nssec8 category. This is done according to nssec8 category distributions among the general population by sex and age groups according to ONS data (DC6114EW and DC6206SC datasets).\nAn individual among those sharing the same 5-year age group (see code for details of age groups for under 18), sex and nssec8 category is drawn from the participants of the UK Time Use Survey. This adds the id_TUS_hh, id_TUS_p, pwkstat, soc2010, sic1d2007, sic2d2007, netPayWeekly and workedHoursWeekly fields. Note that the netPayWeekly and workedHoursWeekly fields have a low response rate among participants of the survey. For that reason, we have a added a much more detailed modelling of income, see below, that includes spatial differences at region level."
  },
  {
    "objectID": "modelling_methods.html#bmi-data",
    "href": "modelling_methods.html#bmi-data",
    "title": "9  Modelling methods",
    "section": "9.2 BMI data",
    "text": "9.2 BMI data\nBody Max Index (BMI) is calculated for each individual from the Health Survey for England 2019 (access needs to be requested to the UK Data Service). This calculation is completely independent from the PSM to the HSE 2017, and therefore the new BMI values will not fit within the categories indicated by this earlier PSM. As the BMI variable is not necessarily independent from the other health variables (diabetes etc.), the new variable should only be used for studies where all other variables are considered equal. The new variable is continuous (a float).\nAccording to the HSE 2019, the distribution of BMI values should follow figure 1. Socio-economic category was discarded for the modelling as it is not independent from the other variables and “mixed” and “other” ethnicities have been merged due to small sample sizes.\n Figure 1. BMI per age. Columns represent ethnicity (White, Black, Asian, Other), and the rows sex (female, male).\nThe distribution for each age group is a gamma distribution. See figure 2.\n Figure 2. Distribution of BMI values for white females aged 30-34.\nDue to small sample sizes, the BMI is calculated for each individual depending on their age according to a gamma distribution whose mean is the mean for the corrresponding age, sex and ethnicity (thick line in figure 1), but whose variance is only determined by the total variance by sex and ethnicity. The resulting BMI where validated for Bedfordshire, and correlations of 0.93 and 0.97 were found between the mean and variance of the modelled data compared to those for the reference HSE 2019 data. See figure 3. The distribution per age, as in figure 1, were also validated.\n Figure 3. Modelled mean and variance compared to the reference mean and variance from the HSE 2019 data for each of the eight categories of figure 1.\nThe R codes for this modelling are here."
  },
  {
    "objectID": "modelling_methods.html#income-data",
    "href": "modelling_methods.html#income-data",
    "title": "9  Modelling methods",
    "section": "9.3 Income data",
    "text": "9.3 Income data\nThis modelling is mainly based on the 2020 revised edition of the Earnings and hours worked, region by occupation by four-digit SOC: ASHE Table 15 database from ONS. Some percentiles for employees’ gross hourly salaries are provided for each full-time and part-time job according to their four-digit SOC classification per region, and separated by sex.\n\n9.3.1 Methods\nThe data are far from complete (only about 15% of all possible values), especially for the highest deciles. We found that an order 3 polynomial fit was satisfactory for most categories (93.11%) to complete the partially filled SOCs. SOCs with too many missing values are given the value for the category that is immediately higher in the SOC hierarchy. Some jobs appear to have a ‘ceiling’ for the highest percentiles, making the polynomial fit fail. In that case, we have replaced the unknown values by the highest known value in the raw data (as there is no clear and systemic fit for these special cases). In addition, there is no information for the highest decile in all cases, which means that the highest salaries are underestimated (and exceptionally high salaries cannot be obtained). The result of this phase is four tables {male full-time, male part-time, female full-time, female part-time} containing the coefficients of the fitted order 3 polynomial, with an optional ceiling percentile when relevant.\nA percentile is chosen randomly (uniformly) for each individual, and the salary is then deduced according to their full-time/part-time status, region, sex and SOC category. A basic hourly salary column is added to the unprocessed SPC data, as well as a corresponding annual salary based on their estimated hours worked per day, according to the Time Use Survey matching. In addition, we repeat this process for all individuals that are categorised as ‘Self-employed’ or ‘Employee unspecified’ by the Time Use Survey matching,, as if they were full time employees. These values are recorded in the columns IncomeHAsIF and IncomeYAsIf. We noticed that a high number of employees were given no worked hours by the Time Use Survey. We have added to the IncomeYAsIf column an estimation of their annual salary based on Table 15.9a: Paid hours worked - Total 2020, and also depending on the same four variables as above (full-time/part-time status, region, sex and SOC category).\nIn addition, age data are made available by ONS. Part of the differences that can be observed between different age groups are already taken into account through the fact that the SOC category can evolve during a career. To take into account that dependence, we first run the above method without weighing by age. The results are shown in the age validation section below. The residual impact of age alone is then added to the model in the following way. When the percentile is drawn for a specific individual, it is morphed to fit within the usual percentage range accessible to that age category. The function that operates this morphing is inferred beforehand and takes into account the salary distribution per age computed by the previous non-age weighted iteration of the modelling (see figure - TBA - for a more detailed description of this function).\nThe R codes for this modelling are here.\nThe methods are validated in the next section. Since it is not possible to optimise every criterion at once, this next section can also be used as a reference to re-adjust some values to match exactly the ONS estimated means for one particular criterion of interest.\n\n\n9.3.2 Comparison to reference values from ONS\nWe compare the results of the modelling to the raw datasets from ONS.\n\nMod for modelled\nM for male\nF for female\nH for hourly gross salary\nY for annual gross salary\nFT for full-Time\nPT for part-Time\nOnly individuals recorded as employees (i.e. not self-employed) are taken into account in this section.\n\nNumber of employees per sex and full-time/part-time classification\nThe numbers given by ONS vary from dataset to dataset and are reported by ONS as indicative only. For the modelled values, we give the total number of individuals with a non-zero salary in each category.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nAll\nFT\nPT\nM\nM FT\nM PT\nF\nF FT\nF PT\n\n\n\n\nONS tot\n22-26k\n16-19k\n6-8k\n11-13k\n9-11k\n1.5-2k\n11-13k\n6.5-7.5k\n4.5-5.5k\n\n\nMod tot H\n23.1k\n18.5k\n4.6k\n11.8k\n11k\n0.8k\n11.3k\n7.5k\n3.8k\n\n\nMod tot Y\n17.6k\n14.8k\n2.8k\n9.4k\n8.9k\n0.5k\n8.2k\n5.9k\n2.3k\n\n\n\nA significant number of individuals listed as working either full or part time have 0 effective worked hours per day according to the Time Use Survey matching. In those cases, an hourly salary is modelled depending on their SOC, region and sex, as for any other employee, but the annual salary will be displayed as 0. It is possible to estimate their likely true number of hours worked from the same ONS dataset (Table 15.9a: Paid hours worked - Total 2020), also depending on their sex, soc and region. This calculation has been added to the “As If” column.\nHourly gross salary per sex and full-time/part-time classification\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nAll\nFT\nPT\nM\nM FT\nM PT\nF\nF FT\nF PT\n\n\n\n\nONS mean\n17.63\n18.32\n13.93\n18.81\n19.12\n14.69\n16.19\n17.08\n13.68\n\n\nONS median\n13.71\n15.15\n10.38\n14.84\n15.58\n10.12\n12.58\n14.42\n10.47\n\n\nMod mean\n16.45\n17.19\n13.45\n17.50\n17.84\n12.75\n15.35\n16.23\n13.60\n\n\nMod median\n13.55\n14.46\n10.23\n14.27\n14.72\n9.16\n12.79\n14.12\n10.51\n\n\n\nThe median values are quite close to the ONS values, but the mean values are always lower. This is expected, see the description of the modelling above.\nAnnual gross salary per sex and full-time/part-time classification\nOnly values > 0 are retained for these calculations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nAll\nFT\nPT\nM\nM FT\nM PT\nF\nF FT\nF PT\n\n\n\n\nONS mean\n31,646\n38,552\n13,819\n38,421\n42,072\n14,796\n24,871\n33,253\n13,512\n\n\nONS median\n25,886\n31,487\n11,240\n31,393\n33,915\n10,883\n20,614\n28,002\n4,743\n\n\nMod mean\n34,317\n36,595\n22,257\n37,574\n38,496\n20,698\n30,594\n33,729\n22,585\n\n\nMod median\n28,713\n30,942\n17,928\n31,404\n32,382\n17,382\n25,875\n29,028\n18,137\n\n\n\nThe average salary for part-time employees is correct when values equal to 0 are taken into account. This suggests that the total number of hours worked for part-time employees is correct, but the way they are distributed among individuals is not. It could be due to the TUS taking a snapshot of the situation during a particular week, rather than averaging their data over the year. It appears that the TUS matching also overestimates the average number of hours worked for female employees.\nRegional differences (hourly gross salary)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegion\nEast\nEast Midlands\nLondon\nNorth East\nNorth West\nSouth East\nSouth West\nWest Midlands\nYorkshire and The Humber\n\n\n\n\nONS mean\n16.74\n15.87\n23.78\n15.69\n16.36\n17.88\n16.36\n16.34\n15.76\n\n\nONS median\n13.28\n12.65\n18.30\n12.40\n12.90\n14.33\n12.74\n12.92\n12.46\n\n\nMod mean\n16.67\n15.29\n19.39\n15.05\n15.22\n17.34\n15.92\n15.47\n14.41\n\n\nMod median\n13.69\n12.79\n16.25\n12.42\n12.44\n14.84\n13.35\n12.64\n12.44\n\n\n\nThe pearson correlations for mean and median between the modelled and raw values are 0.92 and and 0.93.\nHourly gross salary per one-digit SOC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1d SOC\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\nONS mean\n26.77\n23.38\n18.29\n13.42\n13.35\n10.87\n10.94\n12.23\n10.77\n\n\nONS median\n20.96\n21.34\n15.66\n11.54\n12.04\n10.08\n9.52\n10.93\n9.22\n\n\nMod mean\n21.52\n22.14\n16.00\n12.76\n12.55\n10.49\n10.50\n12.05\n9.87\n\n\nMod median\n17.22\n20.66\n14.12\n11.46\n11.34\n9.71\n9.59\n10.82\n9.12\n\n\n\n\nManagers, directors and senior officials\nProfessional occupations\nAssociate professional and technical occupations\nAdministrative and secretarial occupations\nSkilled trades occupations\nCaring, leisure and other service occupations\nSales and customer service occupations\nProcess, plant and machine operatives\nElementary occupations.\n\nThe pearson correlations for mean and median between the modelled and raw values are 0.98 and 0.98.\nHourly gross salary per age\nThe reference for this table is: Table 6.5a Hourly pay - Gross 2020\nTable before weighting by age:\n\n\n\nAge\n16-17\n18-21\n22-29\n30-39\n40-49\n50-59\n60+\n\n\n\n\nONS mean\n7.21\n9.59\n14.09\n18.13\n20.04\n19.12\n16.32\n\n\nONS median\n6.36\n9.00\n12.26\n15.08\n15.89\n14.39\n12.17\n\n\nMod mean\n12.77\n14.96\n16.33\n16.93\n16.83\n16.66\n16.29\n\n\nMod median\n10.93\n12.71\n13.88\n14.02\n13.96\n13.85\n13.65\n\n\n\nThe pearson correlations for mean and median between the modelled and raw values are 0.92 and 0.92.\nTable after weighting by age:\n\n\n\nAge\n16-17\n18-21\n22-29\n30-39\n40-49\n50-59\n60+\n\n\n\n\nONS mean\n7.21\n9.59\n14.09\n18.13\n20.04\n19.12\n16.32\n\n\nONS median\n6.36\n9.00\n12.26\n15.08\n15.89\n14.39\n12.17\n\n\nMod mean\n9.05\n11.15\n14.87\n17.35\n17.96\n17.47\n15.41\n\n\nMod median\n8.20\n9.51\n12.86\n14.41\n14.78\n14.43\n12.56\n\n\n\nThe pearson correlations for mean and median between the modelled and raw values are 0.99 and 0.99."
  },
  {
    "objectID": "modelling_methods.html#commuting-flows",
    "href": "modelling_methods.html#commuting-flows",
    "title": "9  Modelling methods",
    "section": "9.4 Commuting flows",
    "text": "9.4 Commuting flows\nIn order to distribute each individual of the population to a unique physical workplace, we first created a population of all individual workplaces in England, based on a combination of the Nomis UK Business Counts 2020 dataset and the Nomis Business register and Employment Survey 2015 (see Data sources). The first dataset gives the number of individual workplace counts per industry, using the SIC 2007 industry classification, with imprecise size (i.e. number of employees) bands at MSOA level. The second dataset gives the total number of jobs available at LSOA level per SIC 2007 industry category. We found that the distribution of workplace sizes follows closely a simple 1/x distribution, allowing us to draw for each workplace a size within their band, with sum constraints given by the total number of jobs available, according to the second dataset.\nThe workplace ‘population’ and individual population are then levelled for each SIC 2007 category by removing the exceeding part of whichever dataset lists more items. This takes into account that people and business companies are likely to over-report their working availability (e.g. part time and seasonal contracts are not counted differently than full time contracts, jobseekers or people on maternity leave might report the SIC of their last job). This process can be controlled by a threshold in the parameter file that defines the maximal total proportion of workers or jobs that can be removed. If the two datasets cannot be levelled accordingly, the categories are dropped and the datasets are levelled globally. Tests in the West Yorkshire area have shown than when the level 1 SIC, containing 21 unique categories, is used, 90% of the volume of commuting flows were recovered compared to the Nomis commuting OD matrices at MSOA level.\nThe employees for each workplace are drawn according to the ‘universal law of visitation’, see\n\nSchläpfer M et al. The universal visitation law of human mobility. Nature 593, 522–527 (2021). (DOI)\n\nThis framework predicts that visitors to any destination follow a simple\n\nρ(r,f)= K / (rf)2\n\ndistribution, where ρ(r,f) is the density of visitors coming from a distance r with frequency f and K is a balancing constant depending on the specific area. In the context of commuting, it can be assumed that f = 1. Additionally, we only need to weigh potential employees against each other, which removes the necessity to compute explicitly K. In the West Yorkshire test, we found a Pearson coefficient of 0.7 between the predicted flows when aggregated at MSOA level and the OD matrix at MSOA level available from Nomis."
  },
  {
    "objectID": "data_sources.html#utility-data",
    "href": "data_sources.html#utility-data",
    "title": "10  Data sources",
    "section": "10.1 Utility data",
    "text": "10.1 Utility data\n\nlookUp-GB.csv.gz\nThe look-up table links different geographies of Great Britain together. It is used internally by the model, but can also help the user define their own study area. The following are standard denominations, compatible with ONS fields of the same name. They are based on ONS lookups. See ONS documentation for more details.\n\nOA11CD: Output area codes for the 2011 census (120 to 129 households)\nLSOA11CD & LSOA11NM: Lower-layer Super Output Areas (about 2000 individuals), replaced by Intermediary Zones for Scotland\nMSOA11CD,MSOA11NM: Middle-layer Super Output Areas (about 8000 individuals), replaced by Data Zones for Scotland\nLAD20CD, LAD20NM: Local Authority Districts (314 for England, 22 for Wales and 32 for Scotland)\nITL321CD, ITL321NM, ITL221CD, ITL221NM, ITL121CD & ITL121NM: International Territorial Level, replacing pre-Brexit NUTS European divisions.\nRGN20CD & RGN20NM: Regions of England (NA for other Wales and Scotland)\nCountry: England, Wales or Scotland\n\nIn addition,\n\n“AzureRef”: Name of the geographical unit for the County level data folder inside Azure (Lieutenancy Areas – a.k.a. Ceremonial Counties – for England, Scottish Police Divisions and ITL321NM for Wales) For Wales: ITL321NM\n“GoogleMob” & “OSM” are alternate spellings used by Google and OSM for their data releases."
  },
  {
    "objectID": "data_sources.html#county-level-data",
    "href": "data_sources.html#county-level-data",
    "title": "10  Data sources",
    "section": "10.2 County level data",
    "text": "10.2 County level data\nFiles in this section are grouped by country (England, Wales and Scotland), then date (2012, 2020, 2022, 2032, 2039). The format of a path to an individual file is:\nhttps://ramp0storage.blob.core.windows.net/countydata-v2/[country]/[date]/pop_[area_name].csv.gz\nAs of March 2023, England contains 5 series of 46 files (Dorset is missing), Wales 5 series of 12 files and Scotland is missing.\n\npop_.csv.gz\nThe data is mainly based on the 2011 UK census, the UK Time Use Survey 2014-15 and the health surveys of GB (England, Wales, Scotland). The SPENSER (Synthetic Population Estimation and Scenario Projection) microsimulation model (ref) distributes individuals from the census with MSOA scale constraints into synthetic households with OA constraints. It is able to project this synthetic population in the future according to estimates from the Office for National Statistics (ONS). These data were enriched with some of the content of the other datasets mentioned (the rest of which can be added a posteriori from the identifiers provided). The data have also been complented with a modelling of BMI and salaries. The methods used to join the different datasets are explained in the methods.\nThe fields currently contained are detailed here. They are:\n\npid: Unique person identifier at GB level within SPC\nhid: Unique household identifier at GB level within SPC\nOA11CD: Output Area code of the individual’s home (ONS, 2011 boundaries)\nsex: Sex assigned at birth (DC1117EW, census 2011)\nage: Age in years (DC1117EW, census 2011)\nethnicity: Based on self-report (aggregated from DC2101EW, census 2011)\nnssec8: National Statistics Socio-economic classification (see methods)\nHOUSE_nssec8: National Statistics Socio-economic classification of the reference person of the household (LC4605, census 2011)\nHouse_type: Type of accommodation (based on LC4402EW, census 2011)\nHOUSE_typeCommunal: Type of communal establishment (based on QS420, census 2011)\nHOUSE_NRooms: Number of rooms in the accommodation (LC4404EW, census 2011)\nHOUSE_centralHeat: Presence of central heating (based on LC4402EW, census 2011)\nHOUSE_tenure: Tenure (based on LC4402EW, census 2011)\nHOUSE_NCars: Number of cars (derived from LC4202EW by SPENSER team, census 2011)\nid_HS: unique identifier within the Health Survey (aggregated from the Health surveys from England, Wales and Scotland)\nHEALTH_diabetes: for Scotland and England, has doctor diagnosed diabetes; for Wales, diabetes currently treated (derived from HSE, HSW, SHS)\nHEALTH_bloodpressure: for Scotland and England, Doctor diagnosed high blood pressure; for Wales, high blood pressure currently treated (derived from HSE, HSW, SHS)\nHEALTH_cvd: for England, cardiovascular medication taken in the last 7 days; for Scotland, had cardiovascular condition excluding diabetes / blood pressure; for Wales, any heart condition excluding high blood pressure (derived from HSE, HSW, SHS)\nHEALTH_NMedecines: Number of prescribed medications (derived from HSE, HSW, SHS)\nHEALTH_selfAssessed: Self assessed general health (derived from HSE, HSW, SHS)\nHEALTH_lifeSat: how satisfied with life nowadays? (derived from HSE, HSW, SHS)\nHEALTH_bmi: BMI (see methods)\nid_TUS_hh: serial household identifier field in the UK Time Use Survey 2015\nid_TUS_p: pnum person identifier field in the UK Time Use Survey 2015\npwkstat: Employment status (derived from UK TUS 2015)\nsoc2010: Standard Occupational Classification (derived from UK TUS 2015)\nsic1d2007: Standard Industry Classification of economic activities 2007, 1st level (derived from UK TUS 2015)\nsic2d2007: Standard Industry Classification of economic activities 2007, 2nd level (derived from UK TUS 2015)\nnetPayWeekly: Weekly take home pay after all deductions (derived from UK TUS 2015)\nworkedHoursWeekly: Number of hours per week usually worked in main job or business (derived from UK TUS 2015)\nincomeH: Hourly gross salary for full-time and part-time employees (see methods)\nincomeY: Yearly gross salary for full-time and part-time employees (see methods)\nincomeHAsIf: Hourly gross salary for employees with self employed/other employees as employees of the same industry and with mean hourly worked for the industry when the number of hours is missing (see methods)\nincomeYAsIf: Yearly gross salary for employees with self employed/other employees as employees of the same industry and with mean hourly worked for the industry when the number of hours is missing (see methods)\nESport: Relative probability weight to attend a sport fixture (Experimental, WIP)\nERugby: Relative probability weight to attend a Rugby fixture (Experimental, WIP)\nEConcertM: Relative probability weight to attend a concert primarily targeting young males (Experimental, WIP)\nEConcertF: Relative probability weight to attend a concert primarily targeting young females (Experimental, WIP)\nEConcertMS: Relative probability weight to attend a concert primarily targeting middle-aged males (Experimental, WIP)\nEConcertMS: Relative probability weight to attend a concert primarily targeting middle-aged females (Experimental, WIP)\nEMuseum: Relative probability weight to visit a museum (Experimental, WIP)\neasting: X coordinate of the OA centroid in the British National Grid coordinate system (epsg:27700, source: ONS)\nnorthing: Y coordinate of the OA centroid in the British National Grid coordinate system (epsg:27700, source: ONS)\nlng: X coordinate of the OA centroid in the Longitude/Latitude coordinate system (epsg:4326, derived from ONS)\nlat: Y coordinate of the OA centroid in the Longitude/Latitude coordinate system (epsg:4326, derived from ONS)"
  },
  {
    "objectID": "data_sources.html#national-data",
    "href": "data_sources.html#national-data",
    "title": "10  Data sources",
    "section": "10.3 National data",
    "text": "10.3 National data\n\nbusinessRegistry.csv.gz\nContains a breakdown of all business units (i.e. a single workplace) in Great Britain at LSOA scale, estimated by the project contributors from two nomis datasets: UK Business Counts - local units by industry and employment size band 2020 and Business Register and Employment Survey 2015. Each item contains the size of the unit and its main sic1d07 code in reference to standard Industrial Classification of Economic Activities 2007 (number corresponding to the letter in alphabetical order). It is used to compute commuting flows.\n\n\nGIS/\nContains three GIS datasets of GB in GeoJson format taken from ONS boundaries:\n\nOA_2011_Pop20.geojson at OA level\nLSOA_2011_Pop20.geojson at LSOA level\nMSOA_2011_Pop20.geojson at MSOA level\n\n\n\nQUANT_RAMP_spc.tar.gz\nSee: Milton R, Batty M, Dennett A, dedicated RAMP Spatial Interaction Model GitHub repository. It is used to compute the flows towards schools and retail.\n\n\ntimeAtHomeIncreaseCTY.csv.gz\nThis file is a subset from Google COVID-19 Community Mobility Reports, cropped to GB. It describes the daily reduction in mobility, averaged at county level, due to lockdown and other COVID-19 restrictions between the 15th of February 2020 and 15th of October 2022. Missing values have been replaced by the national average. These values can be used directly to reduce pnothome and increase phometot (and their sub-categories) to simulate more accurately the period.\n\n\ndiariesRef.csv.gz\nContains diaries taken from the UK TUS that can be distributed to the population on a daily basis. They contain weekend days and weekday days. A full description of the fields can be found here."
  },
  {
    "objectID": "developer_guide.html#updating-the-docs",
    "href": "developer_guide.html#updating-the-docs",
    "title": "11  Developer guide",
    "section": "11.1 Updating the docs",
    "text": "11.1 Updating the docs\nThe site is built with Quarto. You can iterate on it locally: cd docs; quarto preview"
  },
  {
    "objectID": "developer_guide.html#code-hygiene",
    "href": "developer_guide.html#code-hygiene",
    "title": "11  Developer guide",
    "section": "11.2 Code hygiene",
    "text": "11.2 Code hygiene\nWe use automated tools to format the code.\ncargo fmt\n\n# Format Markdown docs\nprettier --write *.md\nprettier --write docs/*.qmd --parser markdown\nInstall prettier for Markdown."
  },
  {
    "objectID": "developer_guide.html#some-tips-for-working-with-rust",
    "href": "developer_guide.html#some-tips-for-working-with-rust",
    "title": "11  Developer guide",
    "section": "11.3 Some tips for working with Rust",
    "text": "11.3 Some tips for working with Rust\nThere are two equivalent ways to rebuild and then run the code. First:\ncargo run --release -- devon\nThe -- separates arguments to cargo, the Rust build tool, and arguments to the program itself. The second way:\ncargo build --release\n./target/release/aspics devon\nYou can build the code in two ways – debug and release. There’s a simple tradeoff – debug mode is fast to build, but slow to run. Release mode is slow to build, but fast to run. For the ASPICS codebase, since the input data is so large and the codebase so small, I’d recommend always using --release. If you want to use debug mode, just omit the flag.\nIf you’re working on the Rust code outside of an IDE like VSCode, then you can check if the code compiles much faster by doing cargo check."
  },
  {
    "objectID": "developer_guide.html#docker",
    "href": "developer_guide.html#docker",
    "title": "11  Developer guide",
    "section": "11.4 Docker",
    "text": "11.4 Docker\nWe provide a Dockerfile in case it’s helpful for running, but don’t recommend using it. If you want to, then assuming you have Docker setup:\ndocker build -t spc .\ndocker run --mount type=bind,source=\"$(pwd)\"/data,target=/spc/data -t spc /spc/target/release/spc config/bristol.txt\nThis will make the data directory in your directory available to the Docker image, where it’ll download the large input files and produce the final output."
  },
  {
    "objectID": "code_walkthrough.html#generally-useful-techniques",
    "href": "code_walkthrough.html#generally-useful-techniques",
    "title": "12  Code walkthrough",
    "section": "12.1 Generally useful techniques",
    "text": "12.1 Generally useful techniques\nThe code-base makes use of some techniques that may be generally applicable to other projects, independent of the language chosen.\n\n12.1.1 Split code into two stages\nAgent-based models and spatial interaction models require some kind of input. Often the effort to transform external data into this input can exceed that of the simulation component. Cleanly separating the two problems has some advantages:\n\niterate on the simulation faster, without processing raw data every run\nreuse the prepared input for future projects\nforce thinking about the data model needed by the simulation, and transform the external data into that form\n\nSPC is exactly this first stage, originally split from ASPICS when further uses of the same population data were identified.\n\n\n12.1.2 Explicit data schema\nDynamically typed languages like Python don’t force you to explicitly list the shape of input data. It’s common to read CSV files with pandas, filter and transform the data, and use that throughout the program. This can be quick to start prototyping, but is hard to maintain longer-term. Investing in the process of writing down types:\n\nmakes it easier for somebody new to understand your system – they can first focus on what you’re modeling, instead of how that’s built up from raw data sources\nclarifies what data actually matters to your system; you don’t carry forward unnecessary input\nmakes it impossible to express invalid states\n\nOne example is here – per person and activity, there’s a list of venues the person may visit, along with a probability of going there. If the list of venues and list of probabilities are stored as separate lists or columns, then their length may not match.\n\nreuse the prepared input for future projects\n\nThere’s a variety of techniques for expressing strongly typed data:\n\nprotocol buffers or flatbuffers\nJSON schemas\nPython data classes and optional type hints\nstatically typed languages like Rust\n\n\n\n12.1.3 Type-safe IDs\nSay your data model has many different objects, each with their own ID – people, households, venues, etc. You might store these in a list and use the index as an ID. This is fine, but nothing stops you from confusing IDs and accidentally passing in venue 5 to a function instead of household 5. In Rust, it’s easy to create “wrapper types” like this and let the compiler prevent these mistakes.\nThis technique is also useful when preparing external data. GTFS data describing public transit routes and timetables contains many string IDs – shapes, trips, stops, routes. As soon as you read the raw input, you can store the strings in more precise types that prevent mixing up a stop ID and route ID.\n\n\n12.1.4 Idempotent data preparation\nIf you’re iterating on your initialisation pipeline’s code, you probably don’t want to download a 2GB external file every single run. A common approach is to first test if a file exists and don’t download it again if so. In practice, you may also need to handle unzipping files, showing a progress bar while downloading, and printing clear error messages. This codebase has some common code for doing this in Rust. We intend to publish a separate library to more easily call in your own code.\n\n\n12.1.5 Logging with structure\nIt’s typical to print information as a complex pipeline runs, for the user to track progress and debug problems. But without any sort of organization, it’s hard to follow what steps take a long time or encounter problems. What if your logs could show the logical structure of your pipeline and help you understand where time is spent?\n\nThe screenshot above shows a summary printed at the end of a long pipeline run. It’s immediately obvious that the slowest step is creating commuting flows.\nThis codebase uses the tracing framework for logging, with a custom piece to draw the tree. (We’ll publish this as a separate library once it’s more polished.) The tracing framework is hard to understand, but the main conceptual leap over regular logging framworks is the concept of a span. When your code starts one logical step, you call a method to create a new span, and when it finishes, you close that span. Spans can be nested in any way – create_commuting_flows happens within the larger step of creating population.\n\n\n12.1.6 Determinism\nGiven the same inputs, your code should always produce identical output, no matter where it’s run or how many times. Otherwise, debugging problems becomes very tedious, and it’s more difficult to make conclusions from results. Of course, many projects have a stochastic element – but this should be controlled by a random number generator (RNG) seed, which is part of the input. You vary the seed and repeat the program, then reason about the distribution of results.\nAside from organizing your code to let a single RNG seed influence everything, another possible source of non-determinism is iteration order. In Rust, a HashMap could have different order every time it’s used, so we use a BTreeMap instead when this matters. In Python, dictionaries are ordered. Be sure to check for your language."
  },
  {
    "objectID": "code_walkthrough.html#protocol-buffers",
    "href": "code_walkthrough.html#protocol-buffers",
    "title": "12  Code walkthrough",
    "section": "12.2 Protocol buffers",
    "text": "12.2 Protocol buffers\nSPC uses protocol buffers v2 for output. This has some advantages explained the “explicit data schema” section above.\nNote that we chose proto2 instead of proto3, because proto3 doesn’t support required fields. This is done to allow schemas to evolve better over time, but this isn’t a feature SPC makes use of. There’s no need to have new code work with old data, or vice versa – if the schema is updated, downstream code should adapt accordingly and use the updated input files.\nNote also that protocol buffers don’t easily support type-safe wrappers around numeric IDs, so downstream code has to be careful not to mix up household, venue, and person IDs. For this reason, SPC internally doesn’t use the auto-generated protobuf code until the very end of the pipeline. It’s always possible to be more precise with native Rust types, and convert to the less strict types later."
  },
  {
    "objectID": "code_walkthrough.html#an-example-of-the-power-of-static-type-checking",
    "href": "code_walkthrough.html#an-example-of-the-power-of-static-type-checking",
    "title": "12  Code walkthrough",
    "section": "12.3 An example of the power of static type checking",
    "text": "12.3 An example of the power of static type checking\nImagine we want to add a new activity type to represent people going to university and higher education. SPC already has activities for primary and secondary school, so we’ll probably want to follow those as a guide. In any language, we could search the codebase for relevant terms to get a sense of what to update. In languages like Python without an up-front compilation step, if we fail to update something or write blatantly incorrect code (such as making a typo in variable names or passing a list where a string was expected), we only find out when that code happens to run. In pipelines with many steps and large input files, it could be a while before we reach the problematic code.\nLet’s walk through the same exercise for SPC’s Rust code. We start by adding a new University case to the Activity enum. If we try to compile the code here (with cargo check or an IDE), we immediately get 4 errors.\n\nThree of the errors are in the QUANT module. The first is here. It’s immediately clear that for retail and primary/secondary school, we read in two files from QUANT representing venues where these activities take place and the probability of going to each venue. Even if we were unfamiliar with this codebase, the compiler has told us one thing we’ll need to figure out, and where to wire it up.\n\nThe other error is in the code that writes the protobuf output. Similarly, we need a way to represent university activities in the protobuf scheme.\nExtending an unfamiliar code-base backed by compiler errors is a very guided experience. If you wanted to add more demographic attributes to people or energy use information to households, you don’t need to guess all of the places in the code you’ll need to update. You can just add the field, then let the compiler tell you all places where those objects get created."
  },
  {
    "objectID": "performance.html",
    "href": "performance.html",
    "title": "13  Performance",
    "section": "",
    "text": "The following tables summarizes the resources SPC needs to run in different areas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nstudy_area\nnum_msoas\nnum_households\nnum_people\npb_file_size\nruntime\ncommuting_runtime\nmemory_usage\n\n\n\n\n2012\nEngland/bedfordshire\n74\n245,166\n647,272\n256.83 MiB\n10 seconds\n3 seconds\n849.02 MiB\n\n\n2020\nEngland/bedfordshire\n74\n272,875\n674,044\n271.65 MiB\n9 seconds\n3 seconds\n922.88 MiB\n\n\n2022\nEngland/bedfordshire\n74\n309,706\n703,582\n277.74 MiB\n9 seconds\n3 seconds\n929.80 MiB\n\n\n2032\nEngland/bedfordshire\n74\n309,706\n703,582\n277.74 MiB\n9 seconds\n3 seconds\n929.80 MiB\n\n\n2039\nEngland/bedfordshire\n74\n329,061\n715,797\n278.39 MiB\n11 seconds\n3 seconds\n927.77 MiB\n\n\n2012\nEngland/berkshire\n107\n342,167\n890,543\n356.04 MiB\n14 seconds\n7 seconds\n1.06 GiB\n\n\n2020\nEngland/berkshire\n107\n365,905\n918,258\n373.35 MiB\n14 seconds\n7 seconds\n1.10 GiB\n\n\n2022\nEngland/berkshire\n107\n394,446\n941,655\n368.37 MiB\n14 seconds\n7 seconds\n1.08 GiB\n\n\n2032\nEngland/berkshire\n107\n394,446\n941,655\n368.37 MiB\n14 seconds\n7 seconds\n1.08 GiB\n\n\n2039\nEngland/berkshire\n107\n408,604\n949,986\n367.21 MiB\n14 seconds\n7 seconds\n1.08 GiB\n\n\n2012\nEngland/bristol\n55\n182,299\n448,233\n173.74 MiB\n6 seconds\n2 seconds\n527.23 MiB\n\n\n2020\nEngland/bristol\n55\n196,940\n470,039\n183.99 MiB\n6 seconds\n2 seconds\n547.49 MiB\n\n\n2022\nEngland/bristol\n55\n216,197\n503,014\n192.51 MiB\n7 seconds\n2 seconds\n559.78 MiB\n\n\n2032\nEngland/bristol\n55\n216,197\n503,014\n192.51 MiB\n7 seconds\n2 seconds\n559.78 MiB\n\n\n2039\nEngland/bristol\n55\n227,770\n521,371\n199.72 MiB\n7 seconds\n2 seconds\n573.40 MiB\n\n\n2012\nEngland/buckinghamshire\n99\n99,235\n261,340\n108.30 MiB\n5 seconds\n1 second\n310.38 MiB\n\n\n2020\nEngland/buckinghamshire\n99\n108,999\n271,050\n114.31 MiB\n5 seconds\n1 second\n400.87 MiB\n\n\n2022\nEngland/buckinghamshire\n99\n123,578\n278,548\n112.39 MiB\n5 seconds\n1 second\n393.64 MiB\n\n\n2032\nEngland/buckinghamshire\n99\n123,578\n278,548\n112.39 MiB\n5 seconds\n1 second\n393.64 MiB\n\n\n2039\nEngland/buckinghamshire\n99\n130,393\n281,773\n112.14 MiB\n5 seconds\n1 second\n391.52 MiB\n\n\n2012\nEngland/cambridgeshire\n98\n327,257\n832,980\n323.35 MiB\n11 seconds\n5 seconds\n1013.16 MiB\n\n\n2020\nEngland/cambridgeshire\n98\n348,522\n863,250\n341.16 MiB\n12 seconds\n5 seconds\n1.03 GiB\n\n\n2022\nEngland/cambridgeshire\n98\n377,634\n907,166\n348.75 MiB\n12 seconds\n5 seconds\n1.03 GiB\n\n\n2032\nEngland/cambridgeshire\n98\n377,634\n907,166\n348.75 MiB\n12 seconds\n5 seconds\n1.03 GiB\n\n\n2039\nEngland/cambridgeshire\n98\n392,478\n924,170\n351.39 MiB\n12 seconds\n5 seconds\n1.04 GiB\n\n\n2012\nEngland/cheshire\n139\n441,084\n1,042,065\n402.14 MiB\n16 seconds\n7 seconds\n1.13 GiB\n\n\n2020\nEngland/cheshire\n139\n464,134\n1,070,597\n416.35 MiB\n16 seconds\n7 seconds\n1.46 GiB\n\n\n2022\nEngland/cheshire\n139\n489,476\n1,125,198\n425.27 MiB\n16 seconds\n7 seconds\n1.47 GiB\n\n\n2032\nEngland/cheshire\n139\n489,476\n1,125,198\n425.27 MiB\n16 seconds\n7 seconds\n1.47 GiB\n\n\n2039\nEngland/cheshire\n139\n501,501\n1,149,515\n431.10 MiB\n16 seconds\n7 seconds\n1.48 GiB\n\n\n2012\nEngland/cornwall\n74\n232,659\n549,616\n208.07 MiB\n8 seconds\n2 seconds\n742.92 MiB\n\n\n2020\nEngland/cornwall\n74\n247,105\n577,414\n219.74 MiB\n8 seconds\n3 seconds\n764.95 MiB\n\n\n2022\nEngland/cornwall\n74\n270,134\n634,940\n233.36 MiB\n8 seconds\n3 seconds\n828.45 MiB\n\n\n2032\nEngland/cornwall\n74\n270,134\n634,940\n233.36 MiB\n8 seconds\n3 seconds\n828.45 MiB\n\n\n2039\nEngland/cornwall\n74\n280,546\n658,610\n239.72 MiB\n8 seconds\n3 seconds\n838.14 MiB\n\n\n2012\nEngland/cumbria\n64\n222,586\n498,624\n188.03 MiB\n7 seconds\n2 seconds\n547.33 MiB\n\n\n2020\nEngland/cumbria\n64\n226,893\n499,873\n188.73 MiB\n7 seconds\n2 seconds\n548.52 MiB\n\n\n2022\nEngland/cumbria\n64\n230,206\n499,840\n183.18 MiB\n7 seconds\n2 seconds\n533.99 MiB\n\n\n2032\nEngland/cumbria\n64\n230,206\n499,840\n183.18 MiB\n7 seconds\n2 seconds\n533.99 MiB\n\n\n2039\nEngland/cumbria\n64\n231,202\n498,475\n181.58 MiB\n7 seconds\n2 seconds\n530.96 MiB\n\n\n2012\nEngland/derbyshire\n131\n436,276\n1,035,356\n397.75 MiB\n15 seconds\n7 seconds\n1.12 GiB\n\n\n2020\nEngland/derbyshire\n131\n459,743\n1,064,406\n409.76 MiB\n16 seconds\n8 seconds\n1.44 GiB\n\n\n2022\nEngland/derbyshire\n131\n489,764\n1,122,078\n419.52 MiB\n16 seconds\n7 seconds\n1.45 GiB\n\n\n2032\nEngland/derbyshire\n131\n489,764\n1,122,078\n419.52 MiB\n16 seconds\n7 seconds\n1.45 GiB\n\n\n2039\nEngland/derbyshire\n131\n505,314\n1,152,518\n429.01 MiB\n16 seconds\n8 seconds\n1.47 GiB\n\n\n2012\nEngland/devon\n156\n494,106\n1,165,952\n438.60 MiB\n18 seconds\n8 seconds\n1.49 GiB\n\n\n2020\nEngland/devon\n156\n523,033\n1,212,387\n459.44 MiB\n18 seconds\n8 seconds\n1.53 GiB\n\n\n2022\nEngland/devon\n156\n567,011\n1,304,874\n478.71 MiB\n19 seconds\n9 seconds\n1.64 GiB\n\n\n2032\nEngland/devon\n156\n567,011\n1,304,874\n478.71 MiB\n19 seconds\n9 seconds\n1.64 GiB\n\n\n2039\nEngland/devon\n156\n589,178\n1,342,775\n488.23 MiB\n19 seconds\n9 seconds\n1.66 GiB\n\n\n2012\nEngland/durham\n117\n390,472\n911,601\n349.78 MiB\n12 seconds\n5 seconds\n1.03 GiB\n\n\n2020\nEngland/durham\n117\n407,828\n930,184\n359.59 MiB\n12 seconds\n5 seconds\n1.05 GiB\n\n\n2022\nEngland/durham\n117\n425,611\n952,801\n356.63 MiB\n12 seconds\n5 seconds\n1.04 GiB\n\n\n2032\nEngland/durham\n117\n425,611\n952,801\n356.63 MiB\n12 seconds\n5 seconds\n1.04 GiB\n\n\n2039\nEngland/durham\n117\n434,593\n959,555\n357.66 MiB\n12 seconds\n5 seconds\n1.04 GiB\n\n\n2012\nEngland/east-sussex\n102\n355,257\n827,703\n313.71 MiB\n12 seconds\n5 seconds\n987.31 MiB\n\n\n2020\nEngland/east-sussex\n102\n380,894\n853,970\n324.02 MiB\n12 seconds\n6 seconds\n1006.13 MiB\n\n\n2022\nEngland/east-sussex\n102\n423,181\n895,907\n329.56 MiB\n12 seconds\n5 seconds\n1008.58 MiB\n\n\n2032\nEngland/east-sussex\n102\n423,181\n895,907\n329.56 MiB\n12 seconds\n5 seconds\n1008.58 MiB\n\n\n2039\nEngland/east-sussex\n102\n446,000\n915,014\n335.45 MiB\n12 seconds\n5 seconds\n1020.75 MiB\n\n\n2012\nEngland/east-yorkshire-with-hull\n75\n255,848\n593,271\n227.49 MiB\n8 seconds\n3 seconds\n778.75 MiB\n\n\n2020\nEngland/east-yorkshire-with-hull\n75\n262,609\n602,286\n233.14 MiB\n8 seconds\n3 seconds\n835.04 MiB\n\n\n2022\nEngland/east-yorkshire-with-hull\n75\n272,805\n613,721\n230.34 MiB\n8 seconds\n3 seconds\n824.50 MiB\n\n\n2032\nEngland/east-yorkshire-with-hull\n75\n272,805\n613,721\n230.34 MiB\n8 seconds\n3 seconds\n824.50 MiB\n\n\n2039\nEngland/east-yorkshire-with-hull\n75\n277,770\n617,357\n230.45 MiB\n8 seconds\n3 seconds\n825.00 MiB\n\n\n2012\nEngland/essex\n211\n722,974\n1,786,310\n690.77 MiB\n30 seconds\n19 seconds\n2.06 GiB\n\n\n2020\nEngland/essex\n211\n773,454\n1,857,205\n726.02 MiB\n32 seconds\n20 seconds\n2.13 GiB\n\n\n2022\nEngland/essex\n211\n858,552\n1,981,994\n761.40 MiB\n33 seconds\n20 seconds\n2.19 GiB\n\n\n2032\nEngland/essex\n211\n858,552\n1,981,994\n761.40 MiB\n33 seconds\n20 seconds\n2.19 GiB\n\n\n2039\nEngland/essex\n211\n906,640\n2,042,404\n777.71 MiB\n33 seconds\n21 seconds\n2.21 GiB\n\n\n2012\nEngland/gloucestershire\n107\n365,240\n889,836\n344.16 MiB\n13 seconds\n5 seconds\n1.02 GiB\n\n\n2020\nEngland/gloucestershire\n107\n392,643\n933,909\n362.90 MiB\n13 seconds\n6 seconds\n1.06 GiB\n\n\n2022\nEngland/gloucestershire\n107\n432,216\n1,025,077\n389.56 MiB\n14 seconds\n6 seconds\n1.10 GiB\n\n\n2032\nEngland/gloucestershire\n107\n432,216\n1,025,077\n389.56 MiB\n14 seconds\n6 seconds\n1.10 GiB\n\n\n2039\nEngland/gloucestershire\n107\n453,383\n1,068,484\n403.87 MiB\n14 seconds\n6 seconds\n1.43 GiB\n\n\n2012\nEngland/greater-london\n983\n3,283,305\n8,581,245\n3.27 GiB\n12 minutes\n11 minutes\n11.80 GiB\n\n\n2020\nEngland/greater-london\n983\n3,574,266\n8,983,777\n3.48 GiB\n12 minutes\n11 minutes\n12.22 GiB\n\n\n2022\nEngland/greater-london\n983\n3,997,548\n9,452,049\n3.55 GiB\n12 minutes\n11 minutes\n12.25 GiB\n\n\n2032\nEngland/greater-london\n983\n3,997,548\n9,452,049\n3.55 GiB\n12 minutes\n11 minutes\n12.25 GiB\n\n\n2039\nEngland/greater-london\n983\n4,229,017\n9,688,506\n3.58 GiB\n12 minutes\n11 minutes\n12.95 GiB\n\n\n2012\nEngland/greater-manchester\n346\n1,128,371\n2,745,455\n1.05 GiB\n70 seconds\n53 seconds\n3.56 GiB\n\n\n2020\nEngland/greater-manchester\n346\n1,192,547\n2,840,431\n1.10 GiB\n71 seconds\n54 seconds\n3.66 GiB\n\n\n2022\nEngland/greater-manchester\n346\n1,272,689\n2,974,954\n1.13 GiB\n73 seconds\n55 seconds\n3.69 GiB\n\n\n2032\nEngland/greater-manchester\n346\n1,272,689\n2,974,954\n1.13 GiB\n74 seconds\n56 seconds\n3.69 GiB\n\n\n2039\nEngland/greater-manchester\n346\n1,319,090\n3,049,727\n1.15 GiB\n76 seconds\n58 seconds\n3.73 GiB\n\n\n2012\nEngland/hampshire\n225\n733,611\n1,810,518\n698.03 MiB\n32 seconds\n20 seconds\n2.07 GiB\n\n\n2020\nEngland/hampshire\n225\n777,116\n1,861,250\n721.62 MiB\n32 seconds\n20 seconds\n2.12 GiB\n\n\n2022\nEngland/hampshire\n225\n836,451\n1,931,669\n728.97 MiB\n32 seconds\n20 seconds\n2.12 GiB\n\n\n2032\nEngland/hampshire\n225\n836,451\n1,931,669\n728.97 MiB\n33 seconds\n20 seconds\n2.12 GiB\n\n\n2039\nEngland/hampshire\n225\n867,417\n1,960,190\n735.50 MiB\n33 seconds\n20 seconds\n2.13 GiB\n\n\n2012\nEngland/herefordshire\n23\n79,083\n188,362\n72.21 MiB\n4 seconds\n1 second\n234.89 MiB\n\n\n2020\nEngland/herefordshire\n23\n83,238\n195,194\n74.71 MiB\n4 seconds\n1 second\n239.36 MiB\n\n\n2022\nEngland/herefordshire\n23\n89,574\n209,784\n77.63 MiB\n4 seconds\n1 second\n242.83 MiB\n\n\n2032\nEngland/herefordshire\n23\n89,574\n209,784\n77.63 MiB\n4 seconds\n1 second\n242.83 MiB\n\n\n2039\nEngland/herefordshire\n23\n92,605\n216,508\n79.43 MiB\n4 seconds\n1 second\n245.69 MiB\n\n\n2012\nEngland/hertfordshire\n153\n457,276\n1,160,155\n458.65 MiB\n19 seconds\n11 seconds\n1.56 GiB\n\n\n2020\nEngland/hertfordshire\n153\n494,661\n1,190,043\n477.18 MiB\n19 seconds\n11 seconds\n1.59 GiB\n\n\n2022\nEngland/hertfordshire\n153\n546,573\n1,219,124\n476.55 MiB\n19 seconds\n11 seconds\n1.67 GiB\n\n\n2032\nEngland/hertfordshire\n153\n546,573\n1,219,124\n476.55 MiB\n19 seconds\n11 seconds\n1.67 GiB\n\n\n2039\nEngland/hertfordshire\n153\n575,179\n1,233,573\n476.97 MiB\n19 seconds\n11 seconds\n1.67 GiB\n\n\n2012\nEngland/isle-of-wight\n18\n61,636\n139,732\n53.88 MiB\n3 seconds\n1 second\n188.79 MiB\n\n\n2020\nEngland/isle-of-wight\n18\n65,140\n143,268\n54.99 MiB\n3 seconds\n1 second\n190.45 MiB\n\n\n2022\nEngland/isle-of-wight\n18\n70,496\n151,582\n55.55 MiB\n3 seconds\n1 second\n200.99 MiB\n\n\n2032\nEngland/isle-of-wight\n18\n70,496\n151,582\n55.55 MiB\n3 seconds\n1 second\n200.99 MiB\n\n\n2039\nEngland/isle-of-wight\n18\n72,968\n154,841\n56.14 MiB\n3 seconds\n1 second\n202.13 MiB\n\n\n2012\nEngland/kent\n220\n718,544\n1,793,702\n700.10 MiB\n29 seconds\n17 seconds\n2.08 GiB\n\n\n2020\nEngland/kent\n220\n781,933\n1,873,451\n737.20 MiB\n30 seconds\n18 seconds\n2.15 GiB\n\n\n2022\nEngland/kent\n220\n875,515\n2,008,857\n773.24 MiB\n31 seconds\n19 seconds\n2.21 GiB\n\n\n2032\nEngland/kent\n220\n875,515\n2,008,857\n773.24 MiB\n32 seconds\n19 seconds\n2.21 GiB\n\n\n2039\nEngland/kent\n220\n926,571\n2,069,087\n788.47 MiB\n35 seconds\n19 seconds\n2.23 GiB\n\n\n2012\nEngland/lancashire\n191\n619,861\n1,476,469\n571.94 MiB\n24 seconds\n14 seconds\n1.83 GiB\n\n\n2020\nEngland/lancashire\n191\n640,196\n1,511,896\n589.78 MiB\n24 seconds\n14 seconds\n1.87 GiB\n\n\n2022\nEngland/lancashire\n191\n663,637\n1,567,390\n594.49 MiB\n24 seconds\n14 seconds\n1.87 GiB\n\n\n2032\nEngland/lancashire\n191\n663,637\n1,567,390\n594.49 MiB\n24 seconds\n14 seconds\n1.87 GiB\n\n\n2039\nEngland/lancashire\n191\n674,387\n1,591,908\n600.02 MiB\n25 seconds\n14 seconds\n1.88 GiB\n\n\n2012\nEngland/leicestershire\n120\n370,305\n958,470\n373.02 MiB\n14 seconds\n7 seconds\n1.08 GiB\n\n\n2020\nEngland/leicestershire\n120\n397,467\n1,016,632\n397.28 MiB\n14 seconds\n7 seconds\n1.13 GiB\n\n\n2022\nEngland/leicestershire\n120\n438,413\n1,118,737\n426.12 MiB\n15 seconds\n8 seconds\n1.48 GiB\n\n\n2032\nEngland/leicestershire\n120\n438,413\n1,118,737\n426.12 MiB\n15 seconds\n8 seconds\n1.48 GiB\n\n\n2039\nEngland/leicestershire\n120\n459,655\n1,164,678\n440.87 MiB\n16 seconds\n8 seconds\n1.50 GiB\n\n\n2012\nEngland/lincolnshire\n134\n449,394\n1,064,403\n403.05 MiB\n15 seconds\n7 seconds\n1.43 GiB\n\n\n2020\nEngland/lincolnshire\n134\n475,646\n1,098,403\n419.31 MiB\n15 seconds\n7 seconds\n1.46 GiB\n\n\n2022\nEngland/lincolnshire\n134\n507,295\n1,152,299\n427.55 MiB\n15 seconds\n7 seconds\n1.47 GiB\n\n\n2032\nEngland/lincolnshire\n134\n507,295\n1,152,299\n427.55 MiB\n16 seconds\n7 seconds\n1.47 GiB\n\n\n2039\nEngland/lincolnshire\n134\n523,548\n1,172,923\n430.83 MiB\n16 seconds\n7 seconds\n1.47 GiB\n\n\n2012\nEngland/merseyside\n184\n603,483\n1,399,209\n533.96 MiB\n20 seconds\n11 seconds\n1.75 GiB\n\n\n2020\nEngland/merseyside\n184\n632,617\n1,435,755\n553.33 MiB\n20 seconds\n11 seconds\n1.79 GiB\n\n\n2022\nEngland/merseyside\n184\n665,766\n1,498,518\n570.21 MiB\n20 seconds\n10 seconds\n1.82 GiB\n\n\n2032\nEngland/merseyside\n184\n665,766\n1,498,518\n570.21 MiB\n21 seconds\n11 seconds\n1.82 GiB\n\n\n2039\nEngland/merseyside\n184\n685,165\n1,528,037\n577.48 MiB\n21 seconds\n11 seconds\n1.83 GiB\n\n\n2012\nEngland/norfolk\n110\n374,491\n882,793\n333.07 MiB\n12 seconds\n5 seconds\n1017.16 MiB\n\n\n2020\nEngland/norfolk\n110\n397,770\n916,799\n348.41 MiB\n12 seconds\n5 seconds\n1.02 GiB\n\n\n2022\nEngland/norfolk\n110\n432,187\n982,755\n362.27 MiB\n13 seconds\n5 seconds\n1.04 GiB\n\n\n2032\nEngland/norfolk\n110\n432,187\n982,755\n362.27 MiB\n13 seconds\n5 seconds\n1.04 GiB\n\n\n2039\nEngland/norfolk\n110\n450,068\n1,013,214\n371.39 MiB\n13 seconds\n5 seconds\n1.06 GiB\n\n\n2012\nEngland/northamptonshire\n91\n289,575\n720,263\n284.39 MiB\n10 seconds\n4 seconds\n941.33 MiB\n\n\n2020\nEngland/northamptonshire\n91\n316,553\n762,382\n304.36 MiB\n10 seconds\n4 seconds\n981.14 MiB\n\n\n2022\nEngland/northamptonshire\n91\n352,529\n828,003\n320.81 MiB\n11 seconds\n5 seconds\n1005.64 MiB\n\n\n2032\nEngland/northamptonshire\n91\n352,529\n828,003\n320.81 MiB\n11 seconds\n5 seconds\n1005.64 MiB\n\n\n2039\nEngland/northamptonshire\n91\n370,555\n855,812\n328.03 MiB\n11 seconds\n5 seconds\n1016.86 MiB\n\n\n2012\nEngland/northumberland\n40\n138,928\n315,894\n120.66 MiB\n5 seconds\n1 second\n423.11 MiB\n\n\n2020\nEngland/northumberland\n40\n143,516\n322,616\n121.94 MiB\n5 seconds\n1 second\n423.87 MiB\n\n\n2022\nEngland/northumberland\n40\n148,792\n333,456\n122.06 MiB\n5 seconds\n1 second\n421.48 MiB\n\n\n2032\nEngland/northumberland\n40\n148,792\n333,456\n122.06 MiB\n5 seconds\n1 second\n421.48 MiB\n\n\n2039\nEngland/northumberland\n40\n150,259\n337,186\n122.24 MiB\n5 seconds\n1 second\n421.48 MiB\n\n\n2012\nEngland/north-yorkshire\n138\n460,050\n1,085,067\n413.05 MiB\n16 seconds\n7 seconds\n1.45 GiB\n\n\n2020\nEngland/north-yorkshire\n138\n478,639\n1,107,928\n423.18 MiB\n16 seconds\n7 seconds\n1.47 GiB\n\n\n2022\nEngland/north-yorkshire\n138\n499,392\n1,134,723\n420.60 MiB\n16 seconds\n7 seconds\n1.45 GiB\n\n\n2032\nEngland/north-yorkshire\n138\n499,392\n1,134,723\n420.60 MiB\n16 seconds\n7 seconds\n1.45 GiB\n\n\n2039\nEngland/north-yorkshire\n138\n509,099\n1,143,895\n421.52 MiB\n16 seconds\n7 seconds\n1.46 GiB\n\n\n2012\nEngland/nottinghamshire\n138\n460,022\n1,123,005\n432.35 MiB\n16 seconds\n8 seconds\n1.49 GiB\n\n\n2020\nEngland/nottinghamshire\n138\n486,163\n1,169,489\n453.68 MiB\n16 seconds\n8 seconds\n1.53 GiB\n\n\n2022\nEngland/nottinghamshire\n138\n522,944\n1,248,804\n473.35 MiB\n17 seconds\n8 seconds\n1.56 GiB\n\n\n2032\nEngland/nottinghamshire\n138\n522,944\n1,248,804\n473.35 MiB\n17 seconds\n8 seconds\n1.56 GiB\n\n\n2039\nEngland/nottinghamshire\n138\n543,291\n1,281,812\n482.21 MiB\n18 seconds\n9 seconds\n1.66 GiB\n\n\n2012\nEngland/oxfordshire\n86\n261,235\n671,997\n260.43 MiB\n9 seconds\n3 seconds\n852.84 MiB\n\n\n2020\nEngland/oxfordshire\n86\n274,908\n695,490\n271.62 MiB\n10 seconds\n4 seconds\n918.90 MiB\n\n\n2022\nEngland/oxfordshire\n86\n293,368\n729,866\n275.40 MiB\n10 seconds\n4 seconds\n919.34 MiB\n\n\n2032\nEngland/oxfordshire\n86\n293,368\n729,866\n275.40 MiB\n10 seconds\n4 seconds\n919.34 MiB\n\n\n2039\nEngland/oxfordshire\n86\n303,035\n743,227\n277.51 MiB\n10 seconds\n4 seconds\n922.19 MiB\n\n\n2012\nEngland/rutland\n5\n14,912\n38,314\n16.37 MiB\n3 seconds\n1 second\n54.07 MiB\n\n\n2020\nEngland/rutland\n5\n16,698\n40,381\n17.09 MiB\n3 seconds\n1 second\n57.95 MiB\n\n\n2022\nEngland/rutland\n5\n18,198\n44,193\n18.26 MiB\n3 seconds\n1 second\n60.08 MiB\n\n\n2032\nEngland/rutland\n5\n18,198\n44,193\n18.26 MiB\n3 seconds\n1 second\n60.08 MiB\n\n\n2039\nEngland/rutland\n5\n18,914\n45,659\n18.71 MiB\n3 seconds\n1 second\n61.20 MiB\n\n\n2012\nEngland/shropshire\n62\n197,768\n483,414\n186.29 MiB\n7 seconds\n2 seconds\n550.97 MiB\n\n\n2020\nEngland/shropshire\n62\n211,035\n508,233\n195.76 MiB\n7 seconds\n2 seconds\n568.62 MiB\n\n\n2022\nEngland/shropshire\n62\n228,285\n558,755\n207.29 MiB\n7 seconds\n2 seconds\n740.58 MiB\n\n\n2032\nEngland/shropshire\n62\n228,285\n558,755\n207.29 MiB\n7 seconds\n2 seconds\n740.58 MiB\n\n\n2039\nEngland/shropshire\n62\n236,015\n581,476\n213.23 MiB\n7 seconds\n2 seconds\n749.82 MiB\n\n\n2012\nEngland/somerset\n124\n329,040\n790,346\n303.62 MiB\n11 seconds\n4 seconds\n970.03 MiB\n\n\n2020\nEngland/somerset\n124\n353,976\n822,271\n317.43 MiB\n11 seconds\n4 seconds\n996.71 MiB\n\n\n2022\nEngland/somerset\n124\n388,675\n880,441\n331.61 MiB\n12 seconds\n4 seconds\n1018.53 MiB\n\n\n2032\nEngland/somerset\n124\n388,675\n880,441\n331.61 MiB\n12 seconds\n4 seconds\n1018.53 MiB\n\n\n2039\nEngland/somerset\n124\n406,157\n906,545\n339.87 MiB\n12 seconds\n4 seconds\n1.01 GiB\n\n\n2012\nEngland/south-yorkshire\n172\n566,664\n1,372,435\n528.11 MiB\n20 seconds\n11 seconds\n1.75 GiB\n\n\n2020\nEngland/south-yorkshire\n172\n597,694\n1,418,840\n548.59 MiB\n21 seconds\n11 seconds\n1.79 GiB\n\n\n2032\nEngland/south-yorkshire\n172\n637,411\n1,493,544\n563.91 MiB\n21 seconds\n11 seconds\n1.81 GiB\n\n\n2039\nEngland/south-yorkshire\n172\n659,843\n1,531,313\n575.31 MiB\n22 seconds\n12 seconds\n1.83 GiB\n\n\n2012\nEngland/staffordshire\n143\n464,441\n1,111,144\n425.27 MiB\n16 seconds\n8 seconds\n1.47 GiB\n\n\n2020\nEngland/staffordshire\n143\n486,645\n1,139,752\n437.51 MiB\n16 seconds\n8 seconds\n1.49 GiB\n\n\n2022\nEngland/staffordshire\n143\n510,634\n1,188,857\n444.87 MiB\n17 seconds\n8 seconds\n1.50 GiB\n\n\n2032\nEngland/staffordshire\n143\n510,634\n1,188,857\n444.87 MiB\n17 seconds\n8 seconds\n1.50 GiB\n\n\n2039\nEngland/staffordshire\n143\n522,882\n1,215,006\n452.94 MiB\n17 seconds\n8 seconds\n1.52 GiB\n\n\n2012\nEngland/suffolk\n90\n136,142\n327,349\n128.13 MiB\n5 seconds\n1 second\n440.37 MiB\n\n\n2020\nEngland/suffolk\n90\n146,277\n333,781\n130.90 MiB\n5 seconds\n1 second\n445.14 MiB\n\n\n2022\nEngland/suffolk\n90\n159,882\n344,534\n130.76 MiB\n5 seconds\n1 second\n442.14 MiB\n\n\n2032\nEngland/suffolk\n90\n159,882\n344,534\n130.76 MiB\n5 seconds\n1 second\n442.14 MiB\n\n\n2039\nEngland/suffolk\n90\n166,718\n350,358\n132.54 MiB\n5 seconds\n1 second\n446.24 MiB\n\n\n2012\nEngland/surrey\n151\n458,108\n1,168,112\n456.50 MiB\n21 seconds\n13 seconds\n1.55 GiB\n\n\n2020\nEngland/surrey\n151\n480,930\n1,195,509\n472.89 MiB\n21 seconds\n13 seconds\n1.58 GiB\n\n\n2022\nEngland/surrey\n151\n518,720\n1,214,557\n467.03 MiB\n21 seconds\n13 seconds\n1.56 GiB\n\n\n2032\nEngland/surrey\n151\n518,720\n1,214,557\n467.03 MiB\n21 seconds\n13 seconds\n1.56 GiB\n\n\n2039\nEngland/surrey\n151\n538,941\n1,221,227\n464.71 MiB\n21 seconds\n13 seconds\n1.64 GiB\n\n\n2012\nEngland/tyne-and-wear\n145\n483,909\n1,119,030\n427.35 MiB\n15 seconds\n7 seconds\n1.47 GiB\n\n\n2020\nEngland/tyne-and-wear\n145\n501,383\n1,143,194\n439.09 MiB\n15 seconds\n7 seconds\n1.50 GiB\n\n\n2022\nEngland/tyne-and-wear\n145\n521,777\n1,168,078\n440.03 MiB\n15 seconds\n7 seconds\n1.49 GiB\n\n\n2032\nEngland/tyne-and-wear\n145\n521,777\n1,168,078\n440.03 MiB\n14 seconds\n6 seconds\n1.49 GiB\n\n\n2039\nEngland/tyne-and-wear\n145\n532,652\n1,177,340\n441.36 MiB\n15 seconds\n7 seconds\n1.58 GiB\n\n\n2012\nEngland/warwickshire\n108\n361,467\n896,673\n347.44 MiB\n13 seconds\n6 seconds\n1.03 GiB\n\n\n2020\nEngland/warwickshire\n108\n392,639\n958,833\n373.63 MiB\n14 seconds\n6 seconds\n1.08 GiB\n\n\n2022\nEngland/warwickshire\n108\n432,682\n1,061,955\n405.95 MiB\n15 seconds\n7 seconds\n1.44 GiB\n\n\n2032\nEngland/warwickshire\n108\n432,682\n1,061,955\n405.95 MiB\n14 seconds\n7 seconds\n1.44 GiB\n\n\n2039\nEngland/warwickshire\n108\n454,732\n1,112,230\n424.10 MiB\n15 seconds\n7 seconds\n1.47 GiB\n\n\n2012\nEngland/west-midlands\n314\n958,034\n2,477,391\n990.27 MiB\n56 seconds\n38 seconds\n3.24 GiB\n\n\n2020\nEngland/west-midlands\n314\n1,002,273\n2,572,395\n1.01 GiB\n58 seconds\n40 seconds\n3.33 GiB\n\n\n2022\nEngland/west-midlands\n314\n1,046,146\n2,664,228\n1.04 GiB\n60 seconds\n41 seconds\n3.37 GiB\n\n\n2032\nEngland/west-midlands\n314\n1,079,612\n2,706,242\n1.04 GiB\n61 seconds\n41 seconds\n3.55 GiB\n\n\n2039\nEngland/west-midlands\n314\n1,128,890\n2,787,990\n1.07 GiB\n62 seconds\n42 seconds\n3.59 GiB\n\n\n2012\nEngland/west-sussex\n100\n348,766\n836,646\n321.17 MiB\n11 seconds\n5 seconds\n1004.45 MiB\n\n\n2020\nEngland/west-sussex\n100\n375,837\n871,029\n337.76 MiB\n12 seconds\n5 seconds\n1.01 GiB\n\n\n2022\nEngland/west-sussex\n100\n419,347\n931,573\n350.11 MiB\n12 seconds\n5 seconds\n1.03 GiB\n\n\n2032\nEngland/west-sussex\n100\n419,347\n931,573\n350.11 MiB\n12 seconds\n5 seconds\n1.03 GiB\n\n\n2039\nEngland/west-sussex\n100\n442,292\n958,567\n356.77 MiB\n12 seconds\n5 seconds\n1.04 GiB\n\n\n2012\nEngland/west-yorkshire\n299\n921,242\n2,271,833\n893.87 MiB\n46 seconds\n31 seconds\n3.05 GiB\n\n\n2020\nEngland/west-yorkshire\n299\n963,460\n2,339,931\n930.47 MiB\n48 seconds\n33 seconds\n3.12 GiB\n\n\n2022\nEngland/west-yorkshire\n299\n1,021,830\n2,434,902\n945.77 MiB\n48 seconds\n33 seconds\n3.13 GiB\n\n\n2032\nEngland/west-yorkshire\n299\n1,021,830\n2,434,902\n945.77 MiB\n49 seconds\n33 seconds\n3.13 GiB\n\n\n2039\nEngland/west-yorkshire\n299\n1,053,859\n2,481,358\n957.40 MiB\n49 seconds\n33 seconds\n3.32 GiB\n\n\n2012\nEngland/wiltshire\n89\n285,600\n704,491\n274.58 MiB\n9 seconds\n3 seconds\n921.08 MiB\n\n\n2020\nEngland/wiltshire\n89\n309,159\n735,088\n288.20 MiB\n9 seconds\n3 seconds\n947.43 MiB\n\n\n2022\nEngland/wiltshire\n89\n335,400\n774,105\n292.69 MiB\n10 seconds\n3 seconds\n949.16 MiB\n\n\n2032\nEngland/wiltshire\n89\n335,400\n774,105\n292.69 MiB\n10 seconds\n3 seconds\n949.16 MiB\n\n\n2039\nEngland/wiltshire\n89\n348,866\n792,075\n296.40 MiB\n10 seconds\n3 seconds\n955.08 MiB\n\n\n2012\nEngland/worcestershire\n85\n240,958\n578,628\n221.47 MiB\n8 seconds\n3 seconds\n770.62 MiB\n\n\n2020\nEngland/worcestershire\n85\n255,594\n601,116\n231.59 MiB\n8 seconds\n3 seconds\n790.42 MiB\n\n\n2022\nEngland/worcestershire\n85\n274,309\n644,922\n241.99 MiB\n8 seconds\n3 seconds\n849.84 MiB\n\n\n2032\nEngland/worcestershire\n85\n274,309\n644,922\n241.99 MiB\n8 seconds\n3 seconds\n849.84 MiB\n\n\n2039\nEngland/worcestershire\n85\n283,275\n666,303\n248.38 MiB\n8 seconds\n3 seconds\n861.38 MiB\n\n\n2012\nspecial/northwest_transpennine\n829\n2,653,096\n6,416,497\n2.45 GiB\n5 minutes\n4 minutes\n7.74 GiB\n\n\n2020\nspecial/northwest_transpennine\n829\n2,788,624\n6,616,117\n2.56 GiB\n5 minutes\n4 minutes\n7.95 GiB\n\n\n2022\nspecial/northwest_transpennine\n829\n2,960,285\n6,908,374\n2.62 GiB\n5 minutes\n4 minutes\n8.02 GiB\n\n\n2032\nspecial/northwest_transpennine\n829\n2,960,285\n6,908,374\n2.62 GiB\n5 minutes\n5 minutes\n8.02 GiB\n\n\n2039\nspecial/northwest_transpennine\n829\n3,058,114\n7,059,122\n2.66 GiB\n5 minutes\n5 minutes\n8.08 GiB\n\n\n2012\nWales/bridgend-and-neath-port-talbot\n38\n119,725\n283,159\n108.21 MiB\n5 seconds\n1 second\n382.24 MiB\n\n\n2020\nWales/bridgend-and-neath-port-talbot\n38\n123,909\n289,896\n111.10 MiB\n5 seconds\n1 second\n387.45 MiB\n\n\n2022\nWales/bridgend-and-neath-port-talbot\n38\n124,921\n292,227\n111.51 MiB\n4 seconds\n1 second\n387.72 MiB\n\n\n2032\nWales/bridgend-and-neath-port-talbot\n38\n128,601\n301,529\n113.58 MiB\n5 seconds\n1 second\n390.82 MiB\n\n\n2039\nWales/bridgend-and-neath-port-talbot\n38\n129,740\n307,260\n114.33 MiB\n5 seconds\n1 second\n391.29 MiB\n\n\n2012\nWales/cardiff-and-vale-of-glamorgan\n63\n199,208\n484,182\n187.17 MiB\n6 seconds\n2 seconds\n558.19 MiB\n\n\n2020\nWales/cardiff-and-vale-of-glamorgan\n63\n214,676\n499,272\n194.70 MiB\n7 seconds\n2 seconds\n572.89 MiB\n\n\n2022\nWales/cardiff-and-vale-of-glamorgan\n63\n218,981\n502,763\n196.11 MiB\n6 seconds\n2 seconds\n576.04 MiB\n\n\n2032\nWales/cardiff-and-vale-of-glamorgan\n63\n240,112\n522,526\n199.42 MiB\n7 seconds\n2 seconds\n577.84 MiB\n\n\n2039\nWales/cardiff-and-vale-of-glamorgan\n63\n254,162\n531,549\n201.82 MiB\n7 seconds\n2 seconds\n737.29 MiB\n\n\n2012\nWales/central-valleys\n38\n124,691\n296,581\n115.15 MiB\n5 seconds\n1 second\n396.20 MiB\n\n\n2020\nWales/central-valleys\n38\n130,072\n301,907\n117.77 MiB\n18 seconds\n1 second\n400.97 MiB\n\n\n2022\nWales/central-valleys\n38\n131,383\n303,557\n118.40 MiB\n8 seconds\n1 second\n424.47 MiB\n\n\n2032\nWales/central-valleys\n38\n136,404\n310,032\n118.04 MiB\n5 seconds\n1 second\n421.13 MiB\n\n\n2039\nWales/central-valleys\n38\n138,735\n314,703\n119.17 MiB\n5 seconds\n1 second\n423.02 MiB\n\n\n2012\nWales/conwy-and-denbighshire\n30\n92,732\n211,205\n80.50 MiB\n4 seconds\n1 second\n251.47 MiB\n\n\n2020\nWales/conwy-and-denbighshire\n30\n95,314\n213,302\n81.56 MiB\n4 seconds\n1 second\n253.63 MiB\n\n\n2022\nWales/conwy-and-denbighshire\n30\n95,881\n214,182\n81.85 MiB\n4 seconds\n1 second\n254.21 MiB\n\n\n2032\nWales/conwy-and-denbighshire\n30\n97,683\n218,122\n81.11 MiB\n4 seconds\n1 second\n251.17 MiB\n\n\n2039\nWales/conwy-and-denbighshire\n30\n97,687\n220,933\n80.92 MiB\n4 seconds\n1 second\n249.76 MiB\n\n\n2012\nWales/flintshire-and-wrexham\n38\n122,180\n288,696\n113.32 MiB\n5 seconds\n1 second\n393.63 MiB\n\n\n2020\nWales/flintshire-and-wrexham\n38\n127,660\n292,056\n114.58 MiB\n5 seconds\n1 second\n395.27 MiB\n\n\n2022\nWales/flintshire-and-wrexham\n38\n129,007\n292,644\n115.03 MiB\n5 seconds\n1 second\n396.56 MiB\n\n\n2032\nWales/flintshire-and-wrexham\n38\n134,527\n292,817\n112.37 MiB\n5 seconds\n1 second\n410.92 MiB\n\n\n2039\nWales/flintshire-and-wrexham\n38\n136,425\n293,540\n112.22 MiB\n5 seconds\n1 second\n410.77 MiB\n\n\n2012\nWales/gwent-valleys\n46\n144,178\n341,543\n132.17 MiB\n5 seconds\n1 second\n451.03 MiB\n\n\n2020\nWales/gwent-valleys\n46\n148,386\n344,566\n132.83 MiB\n5 seconds\n1 second\n450.89 MiB\n\n\n2022\nWales/gwent-valleys\n46\n149,374\n345,498\n132.72 MiB\n5 seconds\n1 second\n450.23 MiB\n\n\n2032\nWales/gwent-valleys\n46\n151,842\n347,976\n130.50 MiB\n5 seconds\n1 second\n442.86 MiB\n\n\n2039\nWales/gwent-valleys\n46\n151,729\n350,397\n130.58 MiB\n5 seconds\n1 second\n443.03 MiB\n\n\n2012\nWales/gwynedd\n17\n52,926\n122,595\n48.28 MiB\n3 seconds\n1 second\n141.47 MiB\n\n\n2020\nWales/gwynedd\n17\n55,064\n124,569\n49.28 MiB\n3 seconds\n1 second\n143.70 MiB\n\n\n2022\nWales/gwynedd\n17\n55,683\n125,030\n49.20 MiB\n3 seconds\n1 second\n143.45 MiB\n\n\n2032\nWales/gwynedd\n17\n58,372\n128,844\n49.81 MiB\n3 seconds\n1 second\n143.80 MiB\n\n\n2039\nWales/gwynedd\n17\n59,746\n130,948\n50.64 MiB\n3 seconds\n1 second\n145.62 MiB\n\n\n2012\nWales/isle-of-anglesey\n9\n30,797\n69,919\n27.65 MiB\n3 seconds\n1 second\n96.81 MiB\n\n\n2020\nWales/isle-of-anglesey\n9\n31,366\n69,845\n27.85 MiB\n3 seconds\n1 second\n97.39 MiB\n\n\n2022\nWales/isle-of-anglesey\n9\n31,488\n69,864\n27.91 MiB\n3 seconds\n1 second\n97.71 MiB\n\n\n2032\nWales/isle-of-anglesey\n9\n31,601\n69,502\n27.09 MiB\n3 seconds\n1 second\n95.51 MiB\n\n\n2039\nWales/isle-of-anglesey\n9\n31,337\n69,423\n26.91 MiB\n3 seconds\n1 second\n95.37 MiB\n\n\n2012\nWales/monmouthshire-and-newport\n31\n100,402\n240,491\n94.44 MiB\n4 seconds\n1 second\n280.40 MiB\n\n\n2020\nWales/monmouthshire-and-newport\n31\n104,394\n250,185\n98.11 MiB\n4 seconds\n1 second\n286.97 MiB\n\n\n2022\nWales/monmouthshire-and-newport\n31\n105,481\n253,282\n99.27 MiB\n4 seconds\n1 second\n289.03 MiB\n\n\n2032\nWales/monmouthshire-and-newport\n31\n109,752\n265,785\n102.21 MiB\n4 seconds\n1 second\n371.39 MiB\n\n\n2039\nWales/monmouthshire-and-newport\n31\n111,246\n273,319\n103.90 MiB\n4 seconds\n1 second\n373.82 MiB\n\n\n2012\nWales/powys\n19\n59,028\n132,725\n51.21 MiB\n4 seconds\n1 second\n185.06 MiB\n\n\n2020\nWales/powys\n19\n59,972\n132,328\n50.60 MiB\n4 seconds\n1 second\n183.38 MiB\n\n\n2022\nWales/powys\n19\n60,190\n132,467\n50.46 MiB\n4 seconds\n1 second\n182.88 MiB\n\n\n2032\nWales/powys\n19\n59,586\n133,010\n49.63 MiB\n4 seconds\n1 second\n180.64 MiB\n\n\n2039\nWales/powys\n19\n57,969\n133,514\n49.35 MiB\n4 seconds\n1 second\n179.80 MiB\n\n\n2012\nWales/south-west-wales\n50\n165,004\n383,260\n145.79 MiB\n5 seconds\n1 second\n474.32 MiB\n\n\n2020\nWales/south-west-wales\n50\n170,327\n385,937\n146.53 MiB\n5 seconds\n1 second\n474.47 MiB\n\n\n2022\nWales/south-west-wales\n50\n171,623\n386,901\n147.00 MiB\n5 seconds\n1 second\n476.10 MiB\n\n\n2032\nWales/south-west-wales\n50\n175,897\n392,107\n145.19 MiB\n6 seconds\n1 second\n469.31 MiB\n\n\n2039\nWales/south-west-wales\n50\n176,482\n394,303\n144.53 MiB\n6 seconds\n1 second\n467.47 MiB\n\n\n2012\nWales/swansea\n31\n104,423\n242,128\n93.10 MiB\n4 seconds\n1 second\n276.14 MiB\n\n\n2020\nWales/swansea\n31\n110,304\n247,820\n95.72 MiB\n4 seconds\n1 second\n281.38 MiB\n\n\n2022\nWales/swansea\n31\n111,940\n249,098\n96.10 MiB\n4 seconds\n1 second\n282.16 MiB\n\n\n2032\nWales/swansea\n31\n119,141\n257,653\n98.28 MiB\n4 seconds\n1 second\n285.53 MiB\n\n\n2039\nWales/swansea\n31\n123,450\n262,306\n99.93 MiB\n4 seconds\n1 second\n366.61 MiB\n\n\n\nNotes:\n\npb_file_size refers to the size of the uncompressed protobuf file in data/output/\nThe total runtime is usually dominated by matching workers to businesses, so commuting_runtime gives a breakdown\nMeasuring memory usage of Linux processes isn’t straightforward, so memory_usage should just be a guide\nThese measurements were all taken on one developer’s laptop, and they don’t represent multiple runs. This table just aims to give a general sense of how long running takes.\n\nThat machine has 24 cores, which matters for the parallelized commuting calculation.\n\nThe time usually doesn’t include downloading or decompressing raw data. For some areas, it might!\nscripts/collect_stats.py produces the table above"
  }
]